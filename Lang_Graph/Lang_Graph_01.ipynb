{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d38810e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    message: str\n",
    "    sentiment: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e975c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(state):\n",
    "    print(\"---Analyzing Sentiment---\")\n",
    "    text = state[\"message\"].lower()\n",
    "    \n",
    "    # Simple sentiment analysis\n",
    "    if any(word in text for word in [\"good\", \"great\", \"happy\"]):\n",
    "        return {\"sentiment\": \"positive\"}\n",
    "    if any(word in text for word in [\"bad\", \"sad\", \"terrible\"]):\n",
    "        return {\"sentiment\": \"negative\"}\n",
    "    return {\"sentiment\": \"neutral\"}\n",
    "\n",
    "def positive_response(state):\n",
    "    print(\"---Positive Response---\")\n",
    "    return {\"message\": \"Thank you for the positive feedback! ðŸ˜Š\"}\n",
    "\n",
    "def negative_response(state):\n",
    "    print(\"---Negative Response---\")\n",
    "    return {\"message\": \"Weâ€™re sorry to hear that. How can we improve? ðŸ˜ž\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49122c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "def sentiment_router(state) -> Literal[\"positive_response\", \"negative_response\"]:\n",
    "    if state[\"sentiment\"] == \"positive\":\n",
    "        return \"positive_response\"\n",
    "    return \"negative_response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3050b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Initialize graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"analyze_sentiment\", analyze_sentiment)\n",
    "builder.add_node(\"positive_response\", positive_response)\n",
    "builder.add_node(\"negative_response\", negative_response)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"analyze_sentiment\")\n",
    "builder.add_conditional_edges(\"analyze_sentiment\", sentiment_router)\n",
    "builder.add_edge(\"positive_response\", END)\n",
    "builder.add_edge(\"negative_response\", END)\n",
    "\n",
    "# Compile graph\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fbe1f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Analyzing Sentiment---\n",
      "---Positive Response---\n",
      "{'message': 'Thank you for the positive feedback! ðŸ˜Š', 'sentiment': 'positive'}\n"
     ]
    }
   ],
   "source": [
    "# Invoke the graph with input\n",
    "result = graph.invoke({\"message\": \"I had a great experience!\"})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27460d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Case 1: Person Information Tool ===\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Harsha\n",
      "\n",
      "Who is Harsha?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Harsha is working as a DevOps Engineer.\n",
      "\n",
      "=== Test Case 2: Normal LLM ===\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello! ðŸ˜Š How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "from typing import Any\n",
    "from langchain_core.messages import HumanMessage, AnyMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch API credentials from environment variables\n",
    "api_key = os.getenv(\"AZURE_OPENAI_GPT_4O_API_KEY\")\n",
    "end_point = os.getenv(\"AZURE_OPENAI_GPT_4O_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_GPT_4O_API_VERSION\")\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "llm_client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=end_point,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "\n",
    "# Define the state for LangGraph\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "# Tool: Person Information\n",
    "def get_person_details(person: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve the details of a person.\n",
    "    \"\"\"\n",
    "    return f\"{person} is working as a DevOps Engineer.\"\n",
    "\n",
    "\n",
    "# Node function that decides between LLM and tool call\n",
    "def azure_llm_node(state: MessagesState):\n",
    "    user_message = state[\"messages\"][-1]  # latest message\n",
    "\n",
    "    # Special case: if user asks about a person â†’ use the tool\n",
    "    if \"who is\" in user_message.content.lower():\n",
    "        person = user_message.content.split(\"Who is\")[-1].strip().rstrip(\"?\")\n",
    "        reply = get_person_details(person)\n",
    "        return {\"messages\": [HumanMessage(content=reply)]}\n",
    "\n",
    "    # Otherwise â†’ call GPT-4o\n",
    "    response = llm_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": user_message.content},\n",
    "        ],\n",
    "        max_tokens=256,\n",
    "    )\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "    return {\"messages\": [HumanMessage(content=reply)]}\n",
    "\n",
    "\n",
    "# Build LangGraph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"azure_llm_node\", azure_llm_node)\n",
    "\n",
    "builder.add_edge(START, \"azure_llm_node\")\n",
    "builder.add_edge(\"azure_llm_node\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "\n",
    "# ðŸ§ª Test Case 1: Person Information Tool\n",
    "print(\"\\n=== Test Case 1: Person Information Tool ===\")\n",
    "messages = graph.invoke({\"messages\": [HumanMessage(content=\"Who is Harsha?\", name = \"Harsha\")]})\n",
    "for msg in messages[\"messages\"]:\n",
    "    msg.pretty_print()\n",
    "\n",
    "# ðŸ§ª Test Case 2: Normal GPT-4o response\n",
    "print(\"\\n=== Test Case 2: Normal LLM ===\")\n",
    "messages = graph.invoke({\"messages\": [HumanMessage(content=\"Hello!\") ]})\n",
    "for msg in messages[\"messages\"]:\n",
    "    msg.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64821b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Case 1: Person Information Tool ===\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who is Harsha?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Harsha is working as a DevOps Engineer.\n",
      "\n",
      "=== Test Case 2: Normal LLM ===\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello, how are you?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello! I'm here and ready to help. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "from typing import Any\n",
    "from langchain_core.messages import HumanMessage, AnyMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"AZURE_OPENAI_GPT_4O_API_KEY\")\n",
    "end_point = os.getenv(\"AZURE_OPENAI_GPT_4O_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_GPT_4O_API_VERSION\")\n",
    "\n",
    "llm_client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=end_point,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "# --- Tool: Person Information ---\n",
    "def get_person_details(person: str) -> str:\n",
    "    return f\"{person} is working as a DevOps Engineer.\"\n",
    "\n",
    "# LangGraph state\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "# Node function with tool binding (function calling)\n",
    "def azure_llm_node(state: MessagesState):\n",
    "    user_message = state[\"messages\"][-1]\n",
    "\n",
    "    response = llm_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": user_message.content}],\n",
    "        tools=[\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"get_person_details\",\n",
    "                    \"description\": \"Get information about a person\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"person\": {\"type\": \"string\", \"description\": \"Name of the person\"},\n",
    "                        },\n",
    "                        \"required\": [\"person\"],\n",
    "                    },\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "        tool_choice=\"auto\",  # model decides\n",
    "    )\n",
    "\n",
    "    choice = response.choices[0]\n",
    "\n",
    "    # Agar tool call mila\n",
    "    if choice.finish_reason == \"tool_calls\":\n",
    "        tool_call = choice.message.tool_calls[0]\n",
    "        args = json.loads(tool_call.function.arguments)\n",
    "        result = get_person_details(**args)\n",
    "        return {\"messages\": [HumanMessage(content=result)]}\n",
    "\n",
    "    # Normal LLM reply\n",
    "    reply = choice.message.content\n",
    "    return {\"messages\": [HumanMessage(content=reply)]}\n",
    "\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"azure_llm_node\", azure_llm_node)\n",
    "builder.add_edge(START, \"azure_llm_node\")\n",
    "builder.add_edge(\"azure_llm_node\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# ðŸ§ª Test Case 1: Tool calling\n",
    "print(\"\\n=== Test Case 1: Person Information Tool ===\")\n",
    "messages = graph.invoke({\"messages\": [HumanMessage(content=\"Who is Harsha?\")]})\n",
    "for msg in messages[\"messages\"]:\n",
    "    msg.pretty_print()\n",
    "\n",
    "# ðŸ§ª Test Case 2: Normal conversation\n",
    "print(\"\\n=== Test Case 2: Normal LLM ===\")\n",
    "messages = graph.invoke({\"messages\": [HumanMessage(content=\"Hello, how are you?\")]})\n",
    "for msg in messages[\"messages\"]:\n",
    "    msg.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7023bc55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
