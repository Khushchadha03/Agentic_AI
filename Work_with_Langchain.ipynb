{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4ec4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a bunch of code, so I don't experience feelings, but I'm here and ready to help you with whatever you need. How can I assist you today? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"AZURE_OPENAI_GPT_4O_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_GPT_4O_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_GPT_4O_API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_GPT_4O_DEPLOYMENT_NAME\")\n",
    "\n",
    "chat = AzureChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    openai_api_version=api_version,\n",
    "    deployment_name=deployment_name, \n",
    ")\n",
    "\n",
    "messages = [HumanMessage(content= \"Hello! How are you?\")]\n",
    "\n",
    "response = chat.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67181e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source framework designed to simplify the development of applications that utilize large language models (LLMs), such as OpenAI's GPT, Google Bard, or similar technologies. It provides tools, abstractions, and integrations to enable developers to build more advanced and flexible LLM-powered applications.\n",
      "\n",
      "LangChain aims to help developers manage the increasingly complex needs of AI-based applications by focusing on four key areas:\n",
      "\n",
      "1. **Prompt Engineering**: LangChain provides tools to standardize, modularize, and optimize the creation and manipulation of prompts sent to LLMs.\n",
      "\n",
      "2. **Chaining**: It allows developers to chain together multiple interactions with language models and other tools, enabling multi-step workflows beyond basic question-and-answer systems.\n",
      "\n",
      "3. **Integration with External Data**: It can connect LLMs with external data sources, such as knowledge bases, APIs, databases, or file systems, to retrieve and leverage dynamic and up-to-date information.\n",
      "\n",
      "4. **Long-Term Memory Management**: LangChain enables applications to integrate context or \"memory,\" allowing the system to retain and refer back to previous interactions for richer and more contextual outputs.\n",
      "\n",
      "Developers use LangChain to create applications for a variety of tasks, including chatbots, data analysis, knowledge retrieval, code generation, and more. By abstracting away much of the complexity, this framework empowers developers to focus on building custom AI solutions without having to manually manage low-level details.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"AZURE_OPENAI_GPT_4O_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_GPT_4O_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_GPT_4O_API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_GPT_4O_DEPLOYMENT_NAME\")\n",
    "\n",
    "chat = AzureChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    openai_api_version=api_version,\n",
    "    deployment_name=deployment_name, \n",
    ")\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template= \"You are a helpful Ai assistant. Answer the following: {question}\"\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "response = chain.invoke({\"question\": \"What is Langchain?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f08103f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI assistant providing answers to user queries\n",
      "Human: Who won the FIFA World Cup 2022?\u001b[0m\n",
      "The **2022 FIFA World Cup** was won by **Argentina**. The tournament was held in Qatar, and the final took place on **December 18, 2022**, at the Lusail Iconic Stadium. Argentina defeated **France** in a dramatic penalty shootout after the match ended 3-3 in extra time. \n",
      "\n",
      "This victory marked Argentina's third World Cup title, with their previous wins in **1978** and **1986**. Argentina's captain, **Lionel Messi**, played a pivotal role throughout the tournament and was awarded the **Golden Ball** as the best player of the competition.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      " First Response: The **2022 FIFA World Cup** was won by **Argentina**. The tournament was held in Qatar, and the final took place on **December 18, 2022**, at the Lusail Iconic Stadium. Argentina defeated **France** in a dramatic penalty shootout after the match ended 3-3 in extra time. \n",
      "\n",
      "This victory marked Argentina's third World Cup title, with their previous wins in **1978** and **1986**. Argentina's captain, **Lionel Messi**, played a pivotal role throughout the tournament and was awarded the **Golden Ball** as the best player of the competition.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI assistant providing answers to user queries\n",
      "Human: Who won the FIFA World Cup 2022?\n",
      "AI: The **2022 FIFA World Cup** was won by **Argentina**. The tournament was held in Qatar, and the final took place on **December 18, 2022**, at the Lusail Iconic Stadium. Argentina defeated **France** in a dramatic penalty shootout after the match ended 3-3 in extra time. \n",
      "\n",
      "This victory marked Argentina's third World Cup title, with their previous wins in **1978** and **1986**. Argentina's captain, **Lionel Messi**, played a pivotal role throughout the tournament and was awarded the **Golden Ball** as the best player of the competition.\n",
      "Human: Who was the captain of the winning Team?\u001b[0m\n",
      "The captain of the winning team, **Argentina**, in the **2022 FIFA World Cup** was **Lionel Messi**. \n",
      "\n",
      "Messi had an extraordinary tournament, leading his team with exceptional performances, including scoring twice in the final against France. He also played a crucial role in the penalty shootout, converting his spot kick. His leadership and brilliance on the field were instrumental in securing Argentina's third World Cup title. Additionally, Messi received the **Golden Ball** award as the best player of the tournament, becoming the first player in history to win this award twice (he also won it in 2014).\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      " Second Response: The captain of the winning team, **Argentina**, in the **2022 FIFA World Cup** was **Lionel Messi**. \n",
      "\n",
      "Messi had an extraordinary tournament, leading his team with exceptional performances, including scoring twice in the final against France. He also played a crucial role in the penalty shootout, converting his spot kick. His leadership and brilliance on the field were instrumental in securing Argentina's third World Cup title. Additionally, Messi received the **Golden Ball** award as the best player of the tournament, becoming the first player in history to win this award twice (he also won it in 2014).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import(\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"AZURE_OPENAI_GPT_4O_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_GPT_4O_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_GPT_4O_API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_GPT_4O_DEPLOYMENT_NAME\")\n",
    "\n",
    "chat = AzureChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    openai_api_version=api_version,\n",
    "    deployment_name=deployment_name,\n",
    "    streaming = True,\n",
    "    callbacks = [StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a helpful AI assistant providing answers to user queries\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm = chat,\n",
    "    prompt = prompt,\n",
    "    verbose = True,\n",
    "    memory = memory\n",
    ")\n",
    "\n",
    "response1 = chain({\"question\": \"Who won the FIFA World Cup 2022?\"})\n",
    "print(\"\\n First Response:\", response1[\"text\"])\n",
    "\n",
    "response2 = chain({\"question\": \"Who was the captain of the winning Team?\"})\n",
    "print(\"\\n Second Response:\", response2[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d7b772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  pip install wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9684176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n",
      "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "{'query': {'description': 'query to look up on wikipedia', 'title': 'Query', 'type': 'string'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Page: DeepSeek\\nSummary: Hangzhou DeepSeek Artificial Intelligence Basic Technology Research Co., Ltd., doing business as DeepSeek, is a Chinese artificial intelligence company that develops large language models (LLMs). Based in Hangzhou, Zhejiang, Deepseek is owned and funded by the Chinese hedge fund High-Flyer. DeepSeek was founded in July 2023 by Liang Wenfeng, the co-founder of High-Flyer, who also serves as the CEO for both of the companies. The company launched an eponymous chatbot alongside its DeepSeek-R1 model in January 2025.\\nReleased under the MIT License, DeepSeek-R1 provides responses comparable to other contemporary large language models, such as OpenAI's GPT-4 and o1. Its training cost was reported to be significantly lower than other LLMs. The company claims that it trained its V3 model for US millionâ€”far less than the US million cost for OpenAI's GPT-4 in 2023â€”and using approximately one-tenth the computing power consumed by Meta's comparable model, Llama 3.1. DeepSee\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results =1, doc_content_chars_max=1000)\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "print(tool.name)\n",
    "print(tool.description)\n",
    "print(tool.args)\n",
    "\n",
    "tool.run({\"query\": \"deep seek\"})\n",
    "# Explore more tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88b05e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are some creative and edgy company name suggestions for a gaming laptop brand. These names are designed to reflect gaming, performance, and innovation:\n",
      "\n",
      "1. **ShadowForge**\n",
      "2. **PixelFire**\n",
      "3. **CyberVortex**\n",
      "4. **TitanCore**\n",
      "5. **WarpDrive**\n",
      "6. **RogueRealm**\n",
      "7. **InfernoGear**\n",
      "8. **QuantumStrike**\n",
      "9. **NebulaTech**\n",
      "10. **CrimsonEdge**\n",
      "11. **OblivionX**\n",
      "12. **DragonPulse**\n",
      "13. **PhantomRig**\n",
      "14. **BladeMatrix**\n",
      "15. **EclipseForge**\n",
      "16. **Overdrive Systems**\n",
      "17. **StealthByte**\n",
      "18. **ApexEngine**\n",
      "19. **GhostFrame**\n",
      "20. **ViperCore**\n",
      "\n",
      "These names aim to evoke feelings of power, style, and high-tech performance, which are key attributes associated with gaming laptops. Let me know if youâ€™d like variations or help refining the list further!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"AZURE_OPENAI_GPT_4O_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_GPT_4O_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_GPT_4O_API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_GPT_4O_DEPLOYMENT_NAME\")\n",
    "\n",
    "chat = AzureChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    openai_api_version=api_version,\n",
    "    deployment_name=deployment_name, \n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm = chat,\n",
    "    prompt = ChatPromptTemplate.from_template(\"Suggest company names for {product}.\")\n",
    ")\n",
    "\n",
    "result = chain.run({\"product\": \"gaming laptop\" })\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93ecfef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product': 'gaming laptop', 'company_name': 'GameForge', 'description': '\"GameForge: Where Imagination Builds Worlds.\"'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"AZURE_OPENAI_GPT_4O_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_GPT_4O_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_GPT_4O_API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_GPT_4O_DEPLOYMENT_NAME\")\n",
    "\n",
    "chat = AzureChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    openai_api_version=api_version,\n",
    "    deployment_name=deployment_name, \n",
    ")\n",
    "\n",
    "chain_one = LLMChain(\n",
    "    llm = chat,\n",
    "    prompt = ChatPromptTemplate.from_template(\"Give me just in word output. I need a company name for {product}.\"),\n",
    "    output_key = \"company_name\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(\n",
    "    llm = chat,\n",
    "    prompt = ChatPromptTemplate.from_template(\"Write a slogan for {company_name}.\"),\n",
    "    output_key = \"description\"\n",
    ")\n",
    "\n",
    "simple_chain = SequentialChain(\n",
    "    chains= [chain_one, chain_two],\n",
    "    input_variables = [\"product\"],\n",
    "    output_variables = [\"company_name\", \"description\"]\n",
    ")\n",
    "\n",
    "result = simple_chain({\"product\": \"gaming laptop\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15754037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product': 'gaming laptop', 'company_name': 'Gamtronix', 'description': '\"Gamtronix: Power Up Your Play, Redefine the Game!\"'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"AZURE_OPENAI_GPT_4O_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_GPT_4O_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_GPT_4O_API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_GPT_4O_DEPLOYMENT_NAME\")\n",
    "\n",
    "chat = AzureChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    openai_api_version=api_version,\n",
    "    deployment_name=deployment_name, \n",
    ")\n",
    "\n",
    "chain_one = LLMChain(\n",
    "    llm = chat,\n",
    "    prompt = ChatPromptTemplate.from_template(\"Give me just in word output. I need a company name for {product}.\"),\n",
    "    output_key = \"company_name\"\n",
    ")\n",
    "\n",
    "chain_two = LLMChain(\n",
    "    llm = chat,\n",
    "    prompt = ChatPromptTemplate.from_template(\"Write a slogan for {company_name}.\"),\n",
    "    output_key = \"description\"\n",
    ")\n",
    "\n",
    "simple_chain = SequentialChain(\n",
    "    chains= [chain_one, chain_two],\n",
    "    input_variables = [\"product\"],\n",
    "    output_variables = [\"company_name\", \"description\"]\n",
    ")\n",
    "\n",
    "result = simple_chain({\"product\": \"gaming laptop\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee883f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'product': 'gaming laptop', 'description': 'Alienware delivers high-performance gaming PCs, laptops, and accessories with cutting-edge technology, innovative designs, and immersive experiences for gamers worldwide.'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"AZURE_OPENAI_GPT_4O_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_GPT_4O_ENDPOINT\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_GPT_4O_API_VERSION\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_GPT_4O_DEPLOYMENT_NAME\")\n",
    "\n",
    "chat = AzureChatOpenAI(\n",
    "    openai_api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    openai_api_version=api_version,\n",
    "    deployment_name=deployment_name, \n",
    ")\n",
    "\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    What is the best way to describe a company that makes {product}?\n",
    "    Just me just one single company name in plain text in one word only.\n",
    "    No explanation, title, heading etc. The word should explain the company's product.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain_one = LLMChain(\n",
    "    llm = chat,\n",
    "    prompt = first_prompt,\n",
    "    output_key = \"company_name\"\n",
    ")\n",
    "\n",
    "Second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"write a 20 word description for the following companny name: {company_name}\" \n",
    ")\n",
    "\n",
    "chain_two = LLMChain(\n",
    "    llm = chat,\n",
    "    prompt = Second_prompt,\n",
    "    output_key = \"description\"\n",
    ")\n",
    "\n",
    "overall_simple_chain = SequentialChain(\n",
    "    chains= [chain_one, chain_two],\n",
    "    input_variables = [\"product\"],\n",
    "    output_variables = [\"description\"],\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "result = overall_simple_chain({\"product\": \"gaming laptop\"})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
